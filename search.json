[
  {
    "objectID": "datasets.html",
    "href": "datasets.html",
    "title": "Datasets",
    "section": "",
    "text": "source\nsource\nsource"
  },
  {
    "objectID": "datasets.html#hugging-face-datasets",
    "href": "datasets.html#hugging-face-datasets",
    "title": "Datasets",
    "section": "Hugging Face Datasets",
    "text": "Hugging Face Datasets\n\nsource\n\ninplace\n\n inplace (f)\n\n\n@inplace\ndef transformi(b): b[x] = [torch.flatten(TF.to_tensor(o)) for o in b[x]]"
  },
  {
    "objectID": "datasets.html#miniai",
    "href": "datasets.html#miniai",
    "title": "Datasets",
    "section": "miniai",
    "text": "miniai\naround 1:17 there is an explanation of miniai and its installation"
  },
  {
    "objectID": "datasets.html#kwargs",
    "href": "datasets.html#kwargs",
    "title": "Datasets",
    "section": "**kwargs",
    "text": "**kwargs\n@fc.delegates makes imshow kwargs visible. Great."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "macc",
    "section": "",
    "text": "This file will become your README and also the index of your documentation."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "macc",
    "section": "Install",
    "text": "Install\npip install macc"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "macc",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:"
  },
  {
    "objectID": "learner.html",
    "href": "learner.html",
    "title": "Learner",
    "section": "",
    "text": "torch added\nimport matplotlib as mpl\nimport torchvision.transforms.functional as TF\nfrom contextlib import contextmanager\nfrom torch import nn,tensor\nfrom datasets import load_dataset,load_dataset_builder\nfrom macc.datasets import *\nimport logging\nfrom fastcore.test import test_close\ntorch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\ntorch.manual_seed(1)\nmpl.rcParams['image.cmap'] = 'gray'\nsource"
  },
  {
    "objectID": "learner.html#trainlearner-and-momentumlearner",
    "href": "learner.html#trainlearner-and-momentumlearner",
    "title": "Learner",
    "section": "TrainLearner and MomentumLearner",
    "text": "TrainLearner and MomentumLearner\n\nsource\n\nTrainLearner\n\n TrainLearner (model, dls=(0,), loss_func=&lt;function mse_loss&gt;, lr=0.1,\n               cbs=None, opt_func=&lt;class 'torch.optim.sgd.SGD'&gt;)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nvery nice learning point here using a subclass great\n\nsource\n\n\n\nMomentumLearner\n\n MomentumLearner (model, dls, loss_func, lr=None, cbs=None,\n                  opt_func=&lt;class 'torch.optim.sgd.SGD'&gt;, mom=0.85)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nmetrics = MetricsCB(accuracy=MulticlassAccuracy())\ncbs = [DeviceCB(), metrics]\nlearn = MomentumLearner(get_model(), dls, F.cross_entropy, lr=0.1, cbs=cbs)\nlearn.fit(1)\n\n{'accuracy': '0.677', 'loss': '0.953', 'epoch': 0, 'train': 'train'}\n{'accuracy': '0.800', 'loss': '0.575', 'epoch': 0, 'train': 'eval'}\n\n\n\n# metrics = MetricsCB(accuracy=MulticlassAccuracy())\n# cbs = [DeviceCB(), metrics, ProgressCB(plot=True)]\n# learn = MomentumLearner(get_model(), dls, F.cross_entropy, lr=0.1, cbs=cbs)\n# learn.fit(1)"
  },
  {
    "objectID": "learner.html#lrfindercb",
    "href": "learner.html#lrfindercb",
    "title": "Learner",
    "section": "LRFinderCB",
    "text": "LRFinderCB\n\nclass LRFinderCB(Callback):\n    def __init__(self, lr_mult=1.3): fc.store_attr()\n    \n    def before_fit(self, learn):\n        self.lrs,self.losses = [],[]\n        self.min = math.inf\n\n    def after_batch(self, learn):\n        if not learn.training: raise CancelEpochException()\n        self.lrs.append(learn.opt.param_groups[0]['lr'])\n        loss = to_cpu(learn.loss)\n        self.losses.append(loss)\n        if loss &lt; self.min: self.min = loss\n        if loss &gt; self.min*3: raise CancelFitException()\n        for g in learn.opt.param_groups: g['lr'] *= self.lr_mult\n\n\nlrfind = LRFinderCB()\ncbs = [DeviceCB(), lrfind]\nlearn = MomentumLearner(get_model(), dls, F.cross_entropy, lr=1e-4, cbs=cbs)\nlearn.fit(1)\nplt.plot(lrfind.lrs, lrfind.losses)\nplt.xscale('log')\n\n\n\n\nExponentialLR\n\nsource\n\nLRFinderCB\n\n LRFinderCB (gamma=1.3, max_mult=3)\n\nInitialize self. See help(type(self)) for accurate signature.\n\ncbs = [DeviceCB()]\nlearn = MomentumLearner(get_model(), dls, F.cross_entropy, lr=1e-5, cbs=cbs)\nlearn.fit(3, cbs=LRFinderCB())\n\n\n\n\n\nsource\n\n\nshow_doc\n\n show_doc (sym, renderer=None, name:Optional[str]=None, title_level:int=3)\n\nShow signature and docstring for sym\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsym\n\n\nSymbol to document\n\n\nrenderer\nNoneType\nNone\nOptional renderer (defaults to markdown)\n\n\nname\nstr | None\nNone\nOptionally override displayed name of sym\n\n\ntitle_level\nint\n3\nHeading level to use for symbol name\n\n\n\n(jh)lr_find was added in lesson 18. It’s just a shorter way of using LRFinderCB.(nk)around 52:30\n\nMomentumLearner(get_model(), dls, F.cross_entropy, cbs=cbs).lr_find()"
  }
]